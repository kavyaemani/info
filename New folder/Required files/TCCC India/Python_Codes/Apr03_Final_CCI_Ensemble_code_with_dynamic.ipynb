{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apr03_Final CCI Ensemble code",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdk-yDs5oxpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAgJ-yHWJy7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy  as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0gXMKV3J0PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'WB', 'DE', 'MH', 'AP', 'UP', 'PU', 'KA', 'GU', 'RA', 'MP', 'OR', 'TN', 'BI', 'CH', 'HA'\n",
        "# all_state=['RA','BI','CH']\n",
        "all_state = ['WB','DE', 'MH', 'AP', 'UP', 'PU', 'KA', 'GU', 'RA', 'MP', 'OR', 'BI', 'CH','HA','TN']\n",
        "sta_len = len(all_state)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65KmPnWyKLiM",
        "colab_type": "code",
        "outputId": "5b171c11-e9ff-4b10-fc3a-29a1db36bd62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##### reading the file ##########################################################\n",
        "for sta in range(sta_len):\n",
        "  \n",
        "  ##### RAW data ######################################################################################\n",
        "  coke_raw = pd.read_excel('CCI_Sparkling_Consolidated_Data.xlsx',sheet_name=all_state[sta])    #### load raw data here\n",
        "  dt_raw   = coke_raw.copy()\n",
        "  dt_raw   = dt_raw[dt_raw['Date'] >='2015-01-01'].reset_index(drop=True)  ## date change according to model, format:- YYYY-MM-DD\n",
        "  power_bi = dt_raw.copy()\n",
        "  power_bi['Category'] = 'Sparkling'                      # enter category name as needed for power BI\n",
        "  ##### transformed Data ###############################################################################\n",
        "  coke_ols = pd.read_excel('CCI_Sparkling_Ensemble_Data.xlsx',sheet_name=all_state[sta])   #### load transformed data here\n",
        "  dt_ols   = coke_ols.copy()\n",
        "  dt_ols   = dt_ols[dt_ols['Date'] >='2015-01-01'].reset_index(drop=True)  ## date change according to model, format:- YYYY-MM-DD\n",
        "  ##### coefficient data ###############################################################################\n",
        "  coef_ols = pd.read_excel('Spk_coeffs.xlsx', sheet_name =all_state[sta])  #### coefficient data here \n",
        "  dt_coef  = coef_ols.copy() \n",
        "  ######################################################################################################\n",
        "  seed     = pd.read_excel(\"Seed_Results.xlsx\",sheet_name=all_state[sta])  \n",
        "  rf_seed  = seed.at[0,'RF']               # rf  seed\n",
        "  ann_seed = seed.at[0,'ANN']              # ann seed          \n",
        "  ############################### Dynamic Coefficients ################################################\n",
        "\n",
        "  ##########################################################################################################\n",
        "  date1 = '2019-01-01'       # date from which dynamic callculations be calculated, format = 'YYYY-MM-DD'\n",
        "  date2 = '2018-01-01'       # year back as that of 'date1' \n",
        "\n",
        "  due_to = 4                 # mention number of variables(features no. for elasticity calculation) and used in column selection in Due-to\n",
        "  trans  = [0,0,0,0]         # this array is for log transformation, enter for main features for which we calculate elasticity\n",
        "  \n",
        "  \n",
        "  ##############################################################################################################################################\n",
        "  ##############################################################################################################################################\n",
        "  ####### train and test data for rf+ann model ###########################################\n",
        "  z = coke_ols['VolSales'].dropna().count() - 1\n",
        "  y = z - 3\n",
        "  ######## predicted ols column selection ###########################################\n",
        "  list_ols  = list(coke_ols.columns.values) \n",
        "\n",
        "  col_names = list_ols[2:-1]             # Enter column number here and it should be features\n",
        "  col_count = len(col_names)\n",
        "\n",
        "  ################################################################# OLS:- y = mx + c --- code part\n",
        "  Y = coke_ols['VolSales']\n",
        "\n",
        "  xy = 0\n",
        "  for i in range(col_count):\n",
        "    xy += coef_ols['Estimate'][i+1] * coke_ols[coke_ols.columns[i+2]]\n",
        "\n",
        "  xy = coef_ols['Estimate'][0] + xy\n",
        "\n",
        "\n",
        "  ols_mape = np.mean(np.abs ( (Y - xy)/Y ) * 100)          \n",
        "  print(\"MAPE OLS:\",abs(ols_mape))\n",
        "\n",
        "  coke_ols['OLS_Predicted'] = xy   \n",
        "  #######################################################################################################\n",
        "  ############################# RF + ANN model ##########################################################\n",
        "  #######################################################################################################\n",
        "  states_name = coke_ols['States'].unique()\n",
        "  r2_mape = []\n",
        "\n",
        "  for i in range(len(states_name)):\n",
        "      metric_train=[]\n",
        "      metric_test=[]\n",
        "      state = states_name[i]\n",
        "      print('------------------------------------------------------------------------------------------------------')\n",
        "      print('Processing for state: ',state)\n",
        "      pun_coke  = coke_ols[coke_ols['States'] == state]   # Give your state name here\n",
        "      pun_coke  = pun_coke.reset_index( )\n",
        "      #'Market',add below for 7 new states\n",
        "      pun_coke2 = pun_coke.drop(['States','index'],axis=1)  \n",
        "      x=0\n",
        "      # y=56                                                                        \n",
        "      # z=59                                                                        \n",
        "      train_1 = pun_coke2.iloc[x:y, :]\n",
        "      test_1  = pun_coke2.iloc[y:z, :]\n",
        "      forecast_train = pun_coke2.iloc[x:z, :]\n",
        "      forecast_date  = pun_coke2.iloc[z:, :]\n",
        "      train = train_1.drop(['Date'],axis=1)\n",
        "      test  = test_1.drop(['Date'],axis=1)\n",
        "      metric_train.append(str((train.columns).values.tolist()))\n",
        "      metric_test.append(str((train.columns).values.tolist()))\n",
        "      metric_train.append('TRAIN')\n",
        "      metric_test.append('TEST')\n",
        "      \n",
        "      train_target  = train[['VolSales']]\n",
        "      train_feature = train.drop(['VolSales'], axis=1)\n",
        "      test_target   = test[['VolSales']]\n",
        "      test_feature  = test.drop(['VolSales'], axis=1)\n",
        "\n",
        "      \n",
        "      print(train_feature.shape)\n",
        "      print(train_target.shape)\n",
        "      print(test_feature.shape)\n",
        "      print(test_target.shape)\n",
        "      \n",
        "      ################################## Modelling #######################################################\n",
        "      \n",
        "      def mean_absolute_percentage_error(y_true, y_pred): \n",
        "          y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "          return np.mean(np.abs((y_true - y_pred) / y_true)*100)\n",
        "      \n",
        "  ##################################\n",
        "  ###  \n",
        "  ################################## Random Forest ###########################################\n",
        "      #n_estimators=10,random_state=42\n",
        "      #n_estimators=20,max_depth=5,min_samples_split=5,min_samples_leaf=1,\n",
        "      from sklearn.ensemble import RandomForestRegressor\n",
        "      rf = RandomForestRegressor(random_state=rf_seed)    \n",
        "      rf.fit(train_feature,train_target)\n",
        "      Train_pred_rf = rf.predict(train_feature)\n",
        "      Test_pred_rf  = rf.predict(test_feature)\n",
        "      rf.fit(pun_coke2.iloc[x:z, :].drop(['VolSales','Date'], axis=1),pun_coke2.iloc[x:z, :]['VolSales'])\n",
        "      pred_rf = rf.predict(pun_coke2.iloc[z:, :].drop(['VolSales','Date'], axis=1))\n",
        "      \n",
        "      actual_test=list(test_target['VolSales'])\n",
        "      actual_train=list(train_target['VolSales'])\n",
        "\n",
        "      Train_Results=pd.DataFrame(data=actual_train, columns=['Train_Actual'])\n",
        "      Train_Results.insert(loc=1, column='Train_Pred_RF', value=Train_pred_rf)\n",
        "      Test_Results=pd.DataFrame(data=actual_test, columns=['Test_Actual'])\n",
        "      Test_Results.insert(loc=1, column='Test_Pred_RF', value=Test_pred_rf)\n",
        "      \n",
        "\n",
        "      print(\"                           R_square for training data:\",rf.score(train_feature,train_target))\n",
        "      print(\"                           R_square for testing data:\",rf.score(test_feature,test_target))\n",
        "      print(\"                           MAPE for training data:\",mean_absolute_percentage_error(train_target['VolSales'], Train_pred_rf))\n",
        "      print(\"                           MAPE for testing data:\",mean_absolute_percentage_error(test_target['VolSales'], Test_pred_rf))\n",
        "      print(rf.feature_importances_)\n",
        "      fi=pd.DataFrame(rf.feature_importances_,index=train_feature.columns)\n",
        "      # print(fi)\n",
        "      r2_train=rf.score(train_feature,train_target)\n",
        "      r2_test=rf.score(test_feature,test_target)\n",
        "      mape_train=mean_absolute_percentage_error(train_target['VolSales'], Train_pred_rf)\n",
        "      mape_test=mean_absolute_percentage_error(test_target['VolSales'], Test_pred_rf)\n",
        "      \n",
        "\n",
        "    \n",
        "      metric_train.append(r2_train)\n",
        "      metric_train.append(mape_train)\n",
        "      metric_test.append(r2_test)\n",
        "      metric_test.append(mape_test)\n",
        "\n",
        "      rf_mape = (((mape_train)*y)+((mape_test)*(z-y)))/(z+1)\n",
        "      print(\"RF mape:-\",rf_mape)\n",
        "      \n",
        "      ################################## ANN ##############################################\n",
        "      from sklearn.metrics import r2_score\n",
        "      from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "      model_ann = MLPRegressor(hidden_layer_sizes = (256),max_iter=50, batch_size=1,verbose=0,random_state=ann_seed)\n",
        "      print(model_ann.get_params(deep=True))\n",
        "      \n",
        "      model_ann.fit(train_feature, train_target)\n",
        "\n",
        "      \n",
        "      model_ann.fit(pun_coke2.iloc[x:z, :].drop(['VolSales','Date'], axis=1),pun_coke2.iloc[x:z, :]['VolSales'])\n",
        "      pred_ann = model_ann.predict(pun_coke2.iloc[z:, :].drop(['VolSales','Date'], axis=1))\n",
        "      \n",
        "      Train_pred_ann=model_ann.predict(train_feature)\n",
        "      Test_pred_ann=model_ann.predict(test_feature)\n",
        "      \n",
        "      Train_Results.insert(loc=2, column='Train_Pred_ANN', value=Train_pred_ann)\n",
        "      Test_Results.insert(loc=2, column='Test_Pred_ANN', value=Test_pred_ann)\n",
        "      \n",
        "      \n",
        "      print(\"                R_square for training data:\",r2_score(train_target['VolSales'], Train_pred_ann))\n",
        "      print(\"                R_square for testing data:\",r2_score(test_target['VolSales'], Test_pred_ann))\n",
        "      print(\"                MAPE for training data:\",mean_absolute_percentage_error(train_target['VolSales'], Train_pred_ann))\n",
        "      print(\"                MAPE for testing data:\",mean_absolute_percentage_error(test_target['VolSales'], Test_pred_ann))\n",
        "      \n",
        "      \n",
        "      mape_train=mean_absolute_percentage_error(train_target['VolSales'], Train_pred_ann)\n",
        "      mape_test=mean_absolute_percentage_error(test_target['VolSales'], Test_pred_ann)\n",
        "\n",
        "      ann_mape = (((mape_train)*y)+((mape_test)*(z-y)))/(z+1)\n",
        "      print(\"ANN mape:-\",ann_mape)\n",
        "  #############################################################################################################################\n",
        "  #########################################################\n",
        "  estimatorts_train    = [Train_pred_rf, Train_pred_ann]\n",
        "  estimatorts_test     = [Test_pred_rf, Test_pred_ann]\n",
        "  estimatorts_forecast = [pred_rf,pred_ann]\n",
        "\n",
        "  estimatorts_train    = pd.DataFrame(estimatorts_train).T\n",
        "  estimatorts_test     = pd.DataFrame(estimatorts_test).T\n",
        "  estimatorts_forecast = pd.DataFrame(estimatorts_forecast).T\n",
        "\n",
        "  estimatorts=estimatorts_train.append(estimatorts_test)\n",
        "  estimatorts=estimatorts.append(estimatorts_forecast)\n",
        "\n",
        "  estimatorts = estimatorts.rename(columns={0: 'Pred_RF',1:'Pred_ANN'})\n",
        "\n",
        "  estimatorts=estimatorts.reset_index(drop=True)\n",
        "  estimatorts['Pred_OLS'] = coke_ols['OLS_Predicted']\n",
        "  #####################################################################################################\n",
        "  #################################################################\n",
        "  ###################################################################################\n",
        "  w1=(((ols_mape+rf_mape+ann_mape)**2)/(ols_mape)**2)\n",
        "  w2=(((ols_mape+rf_mape+ann_mape)**2)/(rf_mape)**2)\n",
        "  w3=(((ols_mape+rf_mape+ann_mape)**2)/(ann_mape)**2)\n",
        "\n",
        "  w11=w1/(w1+w2+w3)\n",
        "  w22=w2/(w1+w2+w3)\n",
        "  w33=w3/(w1+w2+w3)\n",
        "\n",
        "\n",
        "  estimatorts[\"Ensemble\"] = (w11*estimatorts[\"Pred_OLS\"]) + (w22*estimatorts[\"Pred_RF\"]) + (w33*estimatorts[\"Pred_ANN\"])\n",
        "  ###########################################################################\n",
        "  e=estimatorts[\"Ensemble\"]                       \n",
        "      \n",
        "  estimatorts = estimatorts.reset_index(drop=True)\n",
        "  estimatorts[\"Ensemble\"] = estimatorts[\"Ensemble\"].reset_index(drop=True)\n",
        "  coke_ols['Ensemble']    = estimatorts[\"Ensemble\"]\n",
        "\n",
        "  e = e.reset_index(drop=True)\n",
        "  Y = Y.reset_index(drop=True)\n",
        "\n",
        "  Ensemble_MAPE=np.mean(np.abs((Y-e)/Y)*100)\n",
        "  print(\"MAPE Ensemble:\",abs(Ensemble_MAPE))\n",
        "  #######################################################################################################################\n",
        "\n",
        "  #################### part of DUE_TO ###################################################################################\n",
        "\n",
        "  #######################################################################################################################\n",
        "\n",
        "  list_df      = list(dt_raw.columns.values)    # columns number that covers raw data's features\n",
        "  dt_col_names = list_df[2:due_to+2]   \n",
        "  dt_col_count = len(dt_col_names)  \n",
        "  due_to_varb  = len(dt_col_names)              # features being used in Due_tos for loop       \n",
        "  sale_ind     = pd.DatetimeIndex(dt_raw['Date']).year.nunique()  # no. of times Sales Index calculation should repeat\n",
        "                                                                                  \n",
        "  ####################### Due-To calculations #######################################################################\n",
        "  ###################################################################################################################\n",
        "\n",
        "  ####################### Due-To calculations #######################################################################\n",
        "\n",
        "  Due_to = pd.DataFrame()\n",
        "  ##### Difference YOY  ###########################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    Due_to[dt_col_names[i]+'_Diff_YOY'] = dt_raw[dt_col_names[i]].diff(periods = 12)\n",
        "  ##### Difference MOM  ########################################################################################################### \n",
        "  for i in range(due_to_varb):\n",
        "    Due_to[dt_col_names[i]+'_Diff_MOM'] = dt_raw[dt_col_names[i]].diff(periods = 1)\n",
        "  ##### DT of variables  ##########################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    Due_to['DT_'+dt_col_names[i]] = (dt_coef['Estimate'][i+1] * dt_ols[dt_ols.columns[i+2]]) - (dt_coef['Estimate'][i+1] * dt_ols[dt_ols.columns[i+2]].shift(12))\n",
        "    Due_to['DT_'+dt_col_names[i]].fillna(0, inplace=True)\n",
        "  ##### % DT variables  ############################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    Due_to['% DT_'+dt_col_names[i]] = ((Due_to['DT_'+dt_col_names[i]]).to_numpy() / (dt_ols['VolSales']).shift(12)) * 100\n",
        "  #### DT sales index  #############################################################################################################\n",
        "  import datetime\n",
        "  dt_raw['month']       = pd.DatetimeIndex(dt_raw['Date']).month\n",
        "  sales_index           = dt_raw[['Date','month','VolSales']]\n",
        "  x = sales_index.groupby(['month']).mean()\n",
        "  dt_raw['Sales']       = pd.DataFrame(np.tile((x['VolSales']/(sales_index['VolSales']).mean()),sale_ind))  \n",
        "  dt_raw['Sales_Index'] = dt_raw['Sales'].shift(12)\n",
        "  dt_raw.drop(['Sales'], axis=1, inplace=True)\n",
        "\n",
        "  for i in range(due_to_varb):\n",
        "    Due_to['DT_'+dt_col_names[i]+'_using_sales_index'] = dt_raw['Sales_Index'] * Due_to['DT_'+dt_col_names[i]]\n",
        "    Due_to['DT_'+dt_col_names[i]+'_using_sales_index'].fillna(0, inplace=True)\n",
        "\n",
        "  for i in range(1):\n",
        "    Due_to['DT Weather Sales Index'] = Due_to['DT_'+dt_col_names[i]+'_using_sales_index'] + Due_to['DT_'+dt_col_names[i+1]+'_using_sales_index'] \n",
        "  ##### DT % sales index  #############################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    Due_to['DT_%'+dt_col_names[i]+'_sales_index'] = ((Due_to['DT_'+dt_col_names[i]+'_using_sales_index']).to_numpy() / (dt_ols['VolSales']).shift(12)) * 100\n",
        "\n",
        "  for i in range(1):\n",
        "    Due_to['DT_%Weather_Sales_Index'] = Due_to['DT_%'+dt_col_names[i]+'_sales_index'] + Due_to['DT_%'+dt_col_names[i+1]+'_sales_index']\n",
        "  ##### DT temp MOM  ##################################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    Due_to['DT_'+dt_col_names[i]+'_MOM'] = Due_to['DT_'+dt_col_names[i]+'_using_sales_index'].diff(periods=1)\n",
        "\n",
        "  Due_to['DT_Weather_MOM'] = Due_to['DT Weather Sales Index'].diff(periods=1)\n",
        "  ##### DT ctualised rolling sums ##################################################################################################################################\n",
        "  Due_to['actualized']=coke_ols.apply(\n",
        "\tlambda row: row['VolSales'] if ~np.isnan(row['VolSales']) else row['Ensemble'],axis=1)\n",
        "\n",
        "  Due_to['actualized_3mm'] = Due_to['actualized'].rolling(3).sum().fillna(0)\n",
        "  Due_to['actualized_6mm'] = Due_to['actualized'].rolling(6).sum().fillna(0)\n",
        "  #######################################################################################################################################\n",
        "\n",
        "  ########################### power Bi DT input--part ################################################################\n",
        "\n",
        "  ########### Diff YOY #####################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi[dt_col_names[i]+'_Diff_YOY'] = Due_to[dt_col_names[i]+'_Diff_YOY']\n",
        "  ########### Diff MOM #####################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi[dt_col_names[i]+'_Diff_MOM'] = Due_to[dt_col_names[i]+'_Diff_MOM']\n",
        "  ########### DT_using sales index #########################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi['DT_'+dt_col_names[i]+'_using_sales_index'] = Due_to['DT_'+dt_col_names[i]+'_using_sales_index']\n",
        "  # power_bi['DT Weather Sales Index'] = Due_to['DT Weather Sales Index']\n",
        "  ########### DT_MOM #######################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi['DT_'+dt_col_names[i]+'_MOM'] = Due_to['DT_'+dt_col_names[i]+'_MOM']\n",
        "  # power_bi['DT_Weather_MOM'] = Due_to['DT_Weather_MOM']\n",
        "  ########### DT_% sales index #############################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi['DT_%'+dt_col_names[i]+'_sales_index'] = Due_to['DT_%'+dt_col_names[i]+'_sales_index']\n",
        "  # power_bi['DT_%Weather_Sales_Index'] = Due_to['DT_%Weather_Sales_Index']\n",
        "  ##########################################################################################################\n",
        "  power_bi['Ensemble'] = coke_ols['Ensemble']\n",
        "  power_bi['Actualised']     = Due_to['actualized']\n",
        "  power_bi['Actualised_3MMT'] = Due_to['actualized_3mm']\n",
        "  power_bi['Actualised_6MMT'] = Due_to['actualized_6mm']\n",
        "  power_bi['3MMT_Ensemble'] = coke_ols['Ensemble'].rolling(3).sum()\n",
        "  power_bi['3MMT_VolSales'] = coke_ols['VolSales'].rolling(3).sum()\n",
        "  power_bi['6MMT_Ensemble'] = coke_ols['Ensemble'].rolling(6).sum()\n",
        "  power_bi['6MMT_VolSales'] = coke_ols['VolSales'].rolling(6).sum()\n",
        "  power_bi['3MMT_Sparkling'] = dt_raw['Total_SPK'].rolling(6).sum()\n",
        "  power_bi['6MMT_Sparkling'] = dt_raw['Total_SPK'].rolling(6).sum()\n",
        "  \n",
        "  ##########################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi[dt_col_names[i]+'3MMT'] = dt_raw[dt_col_names[i]].rolling(3).sum()\n",
        "\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi['3MMT'+dt_col_names[i]+'_using_sales_index'] = Due_to['DT_'+dt_col_names[i]+'_using_sales_index'].rolling(3).sum()\n",
        "  ##############################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi[dt_col_names[i]+'6MMT'] = dt_raw[dt_col_names[i]].rolling(6).sum()\n",
        "\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi['6MMT'+dt_col_names[i]+'_using_sales_index'] = Due_to['DT_'+dt_col_names[i]+'_using_sales_index'].rolling(6).sum()\n",
        "  ##########################################################################################################\n",
        "  ############ power bi melt--part ###############################################################################\n",
        "  df_cat = pd.melt(power_bi, id_vars = ['States','Category', 'Date'], var_name='Metrics')\n",
        "  # df_cat.head(4)\n",
        "\n",
        "  #################################################################################################################\n",
        "  ############################################### Dynamic Coefficients ############################################\n",
        "  #################################################################################################################\n",
        "  ##### Data loading\n",
        "\n",
        "  coke       = coke_ols.copy()            # enter file name\n",
        "  std_wt_row = coke['VolSales'].dropna().count()\n",
        "  coke1      = coke.copy()                                                   # for 'New_due_to' calculation \n",
        "  coke2      = coke.copy()                                                   # 'std_coef_wt' calculation in 'coef' data & New_elasticity calculation\n",
        "  #################################################################################################################################\n",
        "  coef  = coef_ols.copy()                    # enter file name\n",
        "  coef  = coef.iloc[:,0:2]\n",
        "  coke2 = coke2.iloc[:std_wt_row].reset_index(drop=True)\n",
        "  #################################################################################################################################\n",
        "  coke   = coke[coke['Date'] >=date1].reset_index(drop=True)        # based on requirement for calculaiton we change date(YYYY-MM-DD)\n",
        "  no_row = coke.shape[0]                                                     \n",
        "  #################################################################################################################################\n",
        "  coke1 = coke1[coke1['Date'] >=date2].reset_index(drop=True)       # enter one year back as that of coke data\n",
        "  coke1 = coke1.iloc[:no_row].reset_index(drop=True)                                                \n",
        "  #################################################################################################################################\n",
        "  list_1    = list(coke.columns.values) \n",
        "  col_names = list_1[2:-3]\n",
        "  col_count = len(col_names)\n",
        "\n",
        "  # due_to = 4                                 # mention number of variables(features no. for elasticity calculation)\n",
        "  # trans  = [0,0,1,0]                         # this array is for log transformation, enter for main features for which we calculate elasticity\n",
        "  col_names\n",
        "  ###################################################################################################################################\n",
        "  ############################################ Dynamic calculations starts here #####################################################\n",
        "  ####################################################################################################################################\n",
        "  # stadard coefficient weight calculaiton -- table\n",
        "  coef['std_coef'] = 0\n",
        "  for i in range(col_count):\n",
        "    coef['std_coef'].loc[i+1] = (coef['Estimate'][i+1] * (coke2[col_names[i]].std())) / (coke2['VolSales'].std())   \n",
        "\n",
        "  coef['std_coef_wt'] = 0\n",
        "  for i in range(col_count):\n",
        "    coef['std_coef_wt'].loc[i+1] = coef['std_coef'][i+1] / coef['std_coef'].loc[1:col_count].sum(axis=0)\n",
        "  ####################################################################################################################################\n",
        "  # Volume_Contribution_existing -- table\n",
        "\n",
        "  Volume_Contribution_existing = pd.DataFrame()\n",
        "\n",
        "  for i in range(col_count):\n",
        "    col = coke.columns[i+2] \n",
        "    Volume_Contribution_existing[col] = coef['Estimate'][i+1] * coke[coke.columns[i+2]]\n",
        "\n",
        "  Difference = coke['Ensemble'] - coke['OLS_Predicted']\n",
        "\n",
        "  Volume_Contribution_existing = Volume_Contribution_existing.reset_index(drop=True)\n",
        "  Difference = pd.DataFrame(Difference,columns=['Difference']).reset_index(drop=True)\n",
        "  #####################################################################################################################################\n",
        "  # Weighted_Difference_Actual -- table\n",
        "\n",
        "  Weighted_Difference_Actual = pd.DataFrame()\n",
        "\n",
        "  for i in range(col_count):\n",
        "    col = coke.columns[i+2]\n",
        "    Weighted_Difference_Actual[col] = coef['std_coef_wt'][i+1] * Difference['Difference']\n",
        "\n",
        "  Weighted_Difference_Actual = Weighted_Difference_Actual.reset_index(drop=True)\n",
        "  #####################################################################################################################################\n",
        "  #Weighted_Difference_Business_Rules -- table\n",
        "\n",
        "  count_n = Volume_Contribution_existing[Volume_Contribution_existing.columns[1]].count()\n",
        "  a_ar    = col_names[0:col_count-1]\n",
        "\n",
        "  Weighted_Difference_Business_Rules = pd.DataFrame(columns=col_names,index=range(count_n))\n",
        "\n",
        "  for a in a_ar:\n",
        "    for i in range(count_n):\n",
        "      if abs(Weighted_Difference_Actual[a][i]) > 0.5 * abs(Volume_Contribution_existing[a][i]):\n",
        "        if Weighted_Difference_Actual[a][i] > 0:\n",
        "          Weighted_Difference_Business_Rules[a][i] = 0.5 * abs(Volume_Contribution_existing[a][i])\n",
        "        else:\n",
        "          Weighted_Difference_Business_Rules[a][i] = -0.5 * abs(Volume_Contribution_existing[a][i])\n",
        "      else:\n",
        "        Weighted_Difference_Business_Rules[a][i] = Weighted_Difference_Actual[a][i]\n",
        "\n",
        "  Weighted_Difference_Business_Rules[col_names[col_count-1]] = Difference['Difference'] - Weighted_Difference_Business_Rules[list(Weighted_Difference_Business_Rules.columns[0:col_count-1])].sum(axis=1)\n",
        "\n",
        "  Weighted_Difference_Business_Rules = Weighted_Difference_Business_Rules.reset_index(drop=True)\n",
        "  #####################################################################################################################################\n",
        "  # Volume_Contribution+Weighted -- table\n",
        "\n",
        "  Volume_Contribution_Weighted = pd.DataFrame()\n",
        "\n",
        "  for i in range(col_count):\n",
        "    col = coke.columns[i+2]\n",
        "    Volume_Contribution_Weighted[col] = (coef['Estimate'][i+1] * coke[coke.columns[i+2]])+ Weighted_Difference_Business_Rules[Weighted_Difference_Business_Rules.columns[i]]\n",
        "\n",
        "  Volume_Contribution_Weighted = Volume_Contribution_Weighted.reset_index(drop=True)\n",
        "\n",
        "  ols_decomp = Volume_Contribution_Weighted[list(Volume_Contribution_Weighted.columns[0:col_count])].sum(axis=1) + coef['Estimate'][0]\n",
        "  ols_decom_wt = pd.DataFrame(ols_decomp,columns=['ols_decomp']).reset_index(drop=True)\n",
        "  #####################################################################################################################################\n",
        "  # New_beta -- table\n",
        "\n",
        "  New_beta = pd.DataFrame()\n",
        "\n",
        "  for i in range(col_count):\n",
        "    col = coke.columns[i+2]\n",
        "    New_beta[col] = Volume_Contribution_Weighted[Volume_Contribution_Weighted.columns[i]] / coke[coke.columns[i+2]]\n",
        "    New_beta[New_beta.columns[i]].fillna(0, inplace=True)\n",
        "\n",
        "  New_beta = New_beta.reset_index(drop=True)\n",
        "\n",
        "  pct_change = ((coke['Ensemble']-ols_decom_wt['ols_decomp']) / ols_decom_wt['ols_decomp']) * 100\n",
        "  pct_change = pd.DataFrame(pct_change,columns=['pct_change']).reset_index(drop=True)\n",
        "  #####################################################################################################################################\n",
        "  # New_due_to -- table    \n",
        "\n",
        "  New_due_to = pd.DataFrame()\n",
        "\n",
        "  for i in range(due_to):\n",
        "    col = coke.columns[i+2]\n",
        "    New_due_to[col] = (New_beta[New_beta.columns[i]] * coke[coke.columns[i+2]]) - (New_beta[New_beta.columns[i]] * coke1[coke1.columns[i+2]])\n",
        "\n",
        "  New_due_to = New_due_to.reset_index(drop=True)\n",
        "  ######################################################################################################################################\n",
        "  # New_elasticity -- table\n",
        "\n",
        "  ss  = coke2['VolSales'].mean()\n",
        "\n",
        "  New_elasticity = pd.DataFrame()\n",
        "  for i in range(due_to):\n",
        "    if trans[i] == 0:\n",
        "      New_elasticity[col_names[i]] = ( New_beta[col_names[i]] / ss ) * 100        \n",
        "    else:\n",
        "      ss1 = coke2[col_names[i]].mean()               \n",
        "      New_elasticity[col_names[i]] =  ((New_beta[col_names[i]] / ss1) / ss ) * 100\n",
        "  #######################################################################################################################################\n",
        "  # Final_results of 'Dynamic-coefficients' calculations\n",
        "\n",
        "  dynamic_coef = pd.DataFrame()\n",
        "\n",
        "  frames = [coke.iloc[:,0:2], Volume_Contribution_existing, Difference, Weighted_Difference_Actual, Weighted_Difference_Business_Rules,\n",
        "            Volume_Contribution_Weighted, ols_decom_wt, New_beta, pct_change, New_due_to, New_elasticity]\n",
        "\n",
        "  dynamic_coef = pd.concat(frames,axis=1)\n",
        "  ###########################################################################################################################################\n",
        "  ###########################################################################################################################################\n",
        "  estimatorts1 = estimatorts\n",
        "\n",
        "  with pd.ExcelWriter('Sparkling_Feb_Results_{}.xlsx'.format(all_state[sta]),datetime_format  = 'YYYY-MM-DD') as writer:  \n",
        "      coke_ols.to_excel(writer,    index=False, sheet_name = 'Ensemble')        \n",
        "      estimatorts1.to_excel(writer,index=False, sheet_name = 'RF+ANN+OLS')          \n",
        "      Due_to.to_excel(writer,      index=False, sheet_name = 'Due_to')          \n",
        "      power_bi.to_excel(writer,    index=False, sheet_name = 'bi')              \n",
        "      df_cat.to_excel(writer,      index=False, sheet_name = 'Power_BI')\n",
        "      dynamic_coef.to_excel(writer,index=False, sheet_name = 'Dynamic_result')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 9.954708718506636\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  West Bengal\n",
            "(58, 6)\n",
            "(58, 1)\n",
            "(3, 6)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9978581814490043\n",
            "                           R_square for testing data: 0.9923724348510707\n",
            "                           MAPE for training data: 1.7798808673619646\n",
            "                           MAPE for testing data: 15.259745426641713\n",
            "[0.0057539  0.00185072 0.0012276  0.00272311 0.64965026 0.33879441]\n",
            "RF mape:- 2.4034246223696623\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1650, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9870274464573267\n",
            "                R_square for testing data: 0.9569048125026091\n",
            "                MAPE for training data: 4.319344134336163\n",
            "                MAPE for testing data: 11.065019558660254\n",
            "ANN mape:- 4.576080943023841\n",
            "MAPE Ensemble: 3.0291707549176876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 8.986132936891602\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  New Delhi, India\n",
            "(58, 12)\n",
            "(58, 1)\n",
            "(3, 12)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9984552206596289\n",
            "                           R_square for testing data: 0.9890996260134344\n",
            "                           MAPE for training data: 1.2688670678196894\n",
            "                           MAPE for testing data: 9.235445406468791\n",
            "[8.79451922e-03 2.66652254e-03 3.26575860e-03 6.03174533e-03\n",
            " 6.70131974e-01 1.01372823e-05 1.56595546e-05 3.30152595e-05\n",
            " 4.94402010e-04 1.11932202e-04 7.74062263e-05 3.08366928e-01]\n",
            "RF mape:- 1.633881066983038\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 2690, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9907756535085238\n",
            "                R_square for testing data: 0.9589209456571999\n",
            "                MAPE for training data: 3.6545500784733376\n",
            "                MAPE for testing data: 7.272081211108795\n",
            "ANN mape:- 3.7706475513674187\n",
            "MAPE Ensemble: 1.9643636367784074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 3.969399269894794\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Maharashtra\n",
            "(58, 6)\n",
            "(58, 1)\n",
            "(3, 6)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9976819012485962\n",
            "                           R_square for testing data: 0.7559468598990198\n",
            "                           MAPE for training data: 0.8725940240892015\n",
            "                           MAPE for testing data: 1.5777171836008572\n",
            "[0.00457887 0.00224938 0.00263587 0.0026536  0.71651316 0.27136911]\n",
            "RF mape:- 0.8926387894834881\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 430, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.982858574288331\n",
            "                R_square for testing data: -1.1513993742427764\n",
            "                MAPE for training data: 2.1788535787598438\n",
            "                MAPE for testing data: 2.0351539330915305\n",
            "ANN mape:- 2.136757570441057\n",
            "MAPE Ensemble: 1.0441658731977985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 6.256026636633025\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Andhra Pradesh\n",
            "(58, 6)\n",
            "(58, 1)\n",
            "(3, 6)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9972962359819906\n",
            "                           R_square for testing data: 0.9736076665295048\n",
            "                           MAPE for training data: 0.7143455410504376\n",
            "                           MAPE for testing data: 0.7123835782579219\n",
            "[0.00182043 0.0047097  0.00417222 0.00487981 0.94648094 0.03793691]\n",
            "RF mape:- 0.7027289050919215\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1260, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9907927497903493\n",
            "                R_square for testing data: 0.8395428656363129\n",
            "                MAPE for training data: 1.4716739818164246\n",
            "                MAPE for testing data: 0.8504911149664259\n",
            "ANN mape:- 1.4178800691976112\n",
            "MAPE Ensemble: 0.7042912367368745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 8.36240900043774\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Uttar Pradesh\n",
            "(58, 11)\n",
            "(58, 1)\n",
            "(3, 11)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9947985558861949\n",
            "                           R_square for testing data: 0.9686841242271043\n",
            "                           MAPE for training data: 2.9136393726858314\n",
            "                           MAPE for testing data: 16.643934674568722\n",
            "[1.97325562e-02 8.75259370e-03 9.96613162e-04 8.67911119e-03\n",
            " 3.97221593e-03 4.48441236e-03 3.83907024e-04 2.22011595e-05\n",
            " 5.28830072e-06 7.59668689e-05 9.52895134e-01]\n",
            "RF mape:- 3.531014316765877\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1630, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9850126637492228\n",
            "                R_square for testing data: 0.8366772401713878\n",
            "                MAPE for training data: 5.044572697339592\n",
            "                MAPE for testing data: 16.464379485626647\n",
            "ANN mape:- 5.515779917783488\n",
            "MAPE Ensemble: 3.2624616747049795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 7.009590294049698\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Punjab\n",
            "(58, 7)\n",
            "(58, 1)\n",
            "(3, 7)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9957723111921168\n",
            "                           R_square for testing data: 0.9418715120948042\n",
            "                           MAPE for training data: 2.568534494695544\n",
            "                           MAPE for testing data: 21.78388319922125\n",
            "[0.02196251 0.00423537 0.00340084 0.00422897 0.01977321 0.02601479\n",
            " 0.9203843 ]\n",
            "RF mape:- 3.456881456290408\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1210, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9923003068497587\n",
            "                R_square for testing data: 0.9895481175258801\n",
            "                MAPE for training data: 3.0479323610464104\n",
            "                MAPE for testing data: 2.777122477514372\n",
            "ANN mape:- 2.9856684576328214\n",
            "MAPE Ensemble: 3.1606279940536064\n",
            "MAPE OLS: 5.650769113575139\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Karnataka\n",
            "(58, 6)\n",
            "(58, 1)\n",
            "(3, 6)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9892424459535925\n",
            "                           R_square for testing data: 0.9741165183707857\n",
            "                           MAPE for training data: 2.0739925226891525\n",
            "                           MAPE for testing data: 3.135475552967986\n",
            "[0.00969561 0.0068149  0.01070154 0.01507551 0.23672665 0.7209858 ]\n",
            "RF mape:- 2.0919031124979806\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 2820, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9182156283950306\n",
            "                R_square for testing data: 0.9501172674533954\n",
            "                MAPE for training data: 5.617390722654457\n",
            "                MAPE for testing data: 1.8784348064403569\n",
            "ANN mape:- 5.3458704247303155\n",
            "MAPE Ensemble: 2.658250934270371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 8.240638032280552\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Gujarat\n",
            "(58, 6)\n",
            "(58, 1)\n",
            "(3, 6)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9888282294244212\n",
            "                           R_square for testing data: 0.9436931909149044\n",
            "                           MAPE for training data: 1.8409095919661684\n",
            "                           MAPE for testing data: 8.055130496683358\n",
            "[0.02323443 0.00477816 0.00587378 0.0091538  0.70236691 0.25459292]\n",
            "RF mape:- 2.111905610065933\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 0, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9120490668860008\n",
            "                R_square for testing data: 0.9763063390515966\n",
            "                MAPE for training data: 6.412754186112952\n",
            "                MAPE for testing data: 2.2450486442085187\n",
            "ANN mape:- 6.107659495599626\n",
            "MAPE Ensemble: 2.576938470107129\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 10.608509603250159\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Rajasthan\n",
            "(58, 9)\n",
            "(58, 1)\n",
            "(3, 9)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9947528299237919\n",
            "                           R_square for testing data: 0.9614895018184564\n",
            "                           MAPE for training data: 3.4386743489856633\n",
            "                           MAPE for testing data: 33.522921605553336\n",
            "[1.78451018e-02 4.06398038e-03 1.59286783e-03 4.80512158e-03\n",
            " 2.54788338e-03 3.04988451e-02 1.19417285e-04 9.16789118e-05\n",
            " 9.38435104e-01]\n",
            "RF mape:- 4.838901242868201\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 4190, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9746864384664614\n",
            "                R_square for testing data: 0.9449766336517421\n",
            "                MAPE for training data: 7.721159415536985\n",
            "                MAPE for testing data: 10.470319808846634\n",
            "ANN mape:- 7.729648476252985\n",
            "MAPE Ensemble: 5.758011043474919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 18.00810613248946\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Madhya Pradesh\n",
            "(58, 6)\n",
            "(58, 1)\n",
            "(3, 6)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.997636594732155\n",
            "                           R_square for testing data: 0.9526914943985265\n",
            "                           MAPE for training data: 2.0858518822565832\n",
            "                           MAPE for testing data: 16.59678644667375\n",
            "[0.00574647 0.00268908 0.00160602 0.00350391 0.79478595 0.19166857]\n",
            "RF mape:- 2.7543511050145657\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 3930, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9871698179245029\n",
            "                R_square for testing data: 0.8845502611642352\n",
            "                MAPE for training data: 5.997925155131481\n",
            "                MAPE for testing data: 10.699586447587569\n",
            "ANN mape:- 6.128684166780462\n",
            "MAPE Ensemble: 3.1391799303613817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 7.807360138695953\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  orissa\n",
            "(58, 8)\n",
            "(58, 1)\n",
            "(3, 8)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9969319774088929\n",
            "                           R_square for testing data: 0.9060756987272892\n",
            "                           MAPE for training data: 1.4058868118830223\n",
            "                           MAPE for testing data: 8.520564682587285\n",
            "[4.19660473e-03 3.02496396e-03 2.22698166e-02 8.61503667e-03\n",
            " 8.11827726e-01 2.10650116e-04 2.89433884e-04 1.49565768e-01]\n",
            "RF mape:- 1.727469824789954\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 420, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.952662227987413\n",
            "                R_square for testing data: -0.04324389988740496\n",
            "                MAPE for training data: 5.013044558582075\n",
            "                MAPE for testing data: 11.504921347104867\n",
            "ANN mape:- 5.246312071597982\n",
            "MAPE Ensemble: 2.2121052669949197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 15.73956163971099\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Bihar\n",
            "(58, 9)\n",
            "(58, 1)\n",
            "(3, 9)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9976452881271297\n",
            "                           R_square for testing data: 0.9990813678506526\n",
            "                           MAPE for training data: 2.2124603235701708\n",
            "                           MAPE for testing data: 10.303098703903737\n",
            "[1.43840775e-02 2.17240715e-03 1.73541479e-03 8.34289788e-04\n",
            " 5.30584860e-01 1.59857625e-06 7.41262488e-05 1.29158315e-05\n",
            " 4.50200310e-01]\n",
            "RF mape:- 2.568257981915824\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 4340, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9938448717380546\n",
            "                R_square for testing data: 0.9903312675524372\n",
            "                MAPE for training data: 6.104406897517506\n",
            "                MAPE for testing data: 12.320321243022578\n",
            "ANN mape:- 6.306718770727146\n",
            "MAPE Ensemble: 3.1810829462449504\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 9.15309188216427\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Chhattisgarh\n",
            "(58, 10)\n",
            "(58, 1)\n",
            "(3, 10)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9975170075515517\n",
            "                           R_square for testing data: 0.652425577426546\n",
            "                           MAPE for training data: 1.6971751375482924\n",
            "                           MAPE for testing data: 32.274088591857925\n",
            "[2.76148762e-03 1.97575841e-03 2.06497165e-03 5.39638561e-03\n",
            " 7.20658369e-01 3.65540821e-05 1.34140726e-05 1.01216869e-05\n",
            " 2.29711152e-05 2.67059967e-01]\n",
            "RF mape:- 3.149329415377012\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 4250, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9925961581467226\n",
            "                R_square for testing data: -2.2726013313427598\n",
            "                MAPE for training data: 4.240534964182325\n",
            "                MAPE for testing data: 24.373912828388494\n",
            "ANN mape:- 5.146334942060328\n",
            "MAPE Ensemble: 3.9476581497271783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 13.879809807694542\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Haryana\n",
            "(58, 6)\n",
            "(58, 1)\n",
            "(3, 6)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9971207739644302\n",
            "                           R_square for testing data: 0.9741278478314932\n",
            "                           MAPE for training data: 2.0934067673867847\n",
            "                           MAPE for testing data: 12.009310326043066\n",
            "[0.01120004 0.00369271 0.00494812 0.00630845 0.84430433 0.12954636]\n",
            "RF mape:- 2.5394439272026244\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 920, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9651350910828409\n",
            "                R_square for testing data: 0.940946411803869\n",
            "                MAPE for training data: 6.700230159420702\n",
            "                MAPE for testing data: 6.375907708970058\n",
            "ANN mape:- 6.57646890924695\n",
            "MAPE Ensemble: 2.881590321609833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 5.077633539686178\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Tamil Nadu\n",
            "(34, 6)\n",
            "(34, 1)\n",
            "(3, 6)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9839009583340625\n",
            "                           R_square for testing data: 0.9837434065860245\n",
            "                           MAPE for training data: 1.7163860315638706\n",
            "                           MAPE for testing data: 2.1322083389036073\n",
            "[0.01212083 0.01318841 0.00512738 0.01298832 0.66144588 0.29512918]\n",
            "RF mape:- 1.704046054996906\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1000, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9113299328002507\n",
            "                R_square for testing data: -0.21027452653498857\n",
            "                MAPE for training data: 4.435010380915021\n",
            "                MAPE for testing data: 4.536798949927071\n",
            "ANN mape:- 4.326335521076103\n",
            "MAPE Ensemble: 2.1345410488365046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDqFwxZtrBve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wb = pd.read_excel('Sparkling_Feb_Results_WB.xlsx',sheet_name='Power_BI') \n",
        "de = pd.read_excel('Sparkling_Feb_Results_DE.xlsx',sheet_name='Power_BI')  \n",
        "mh = pd.read_excel('Sparkling_Feb_Results_MH.xlsx',sheet_name='Power_BI') \n",
        "ap = pd.read_excel('Sparkling_Feb_Results_AP.xlsx',sheet_name='Power_BI') \n",
        "up = pd.read_excel('Sparkling_Feb_Results_UP.xlsx',sheet_name='Power_BI') \n",
        "pu = pd.read_excel('Sparkling_Feb_Results_PU.xlsx',sheet_name='Power_BI') \n",
        "ka = pd.read_excel('Sparkling_Feb_Results_KA.xlsx',sheet_name='Power_BI') \n",
        "gu = pd.read_excel('Sparkling_Feb_Results_GU.xlsx',sheet_name='Power_BI') \n",
        "ra = pd.read_excel('Sparkling_Feb_Results_RA.xlsx',sheet_name='Power_BI') \n",
        "mp = pd.read_excel('Sparkling_Feb_Results_MP.xlsx',sheet_name='Power_BI') \n",
        "orr = pd.read_excel('Sparkling_Feb_Results_OR.xlsx',sheet_name='Power_BI') \n",
        "bi = pd.read_excel('Sparkling_Feb_Results_BI.xlsx',sheet_name='Power_BI') \n",
        "ch = pd.read_excel('Sparkling_Feb_Results_CH.xlsx',sheet_name='Power_BI') \n",
        "ha = pd.read_excel('Sparkling_Feb_Results_HA.xlsx',sheet_name='Power_BI') \n",
        "tn = pd.read_excel('Sparkling_Feb_Results_TN.xlsx',sheet_name='Power_BI')\n",
        "\n",
        "merge1=wb.append(de)\n",
        "merge2=merge1.append(mh)\n",
        "merge3=merge2.append(ap)\n",
        "merge4=merge3.append(up)\n",
        "merge5=merge4.append(pu)\n",
        "merge6=merge5.append(ka)\n",
        "merge7=merge6.append(gu)\n",
        "merge8=merge7.append(ra)\n",
        "merge9=merge8.append(mp)\n",
        "merge10=merge9.append(orr)\n",
        "merge11=merge10.append(bi)\n",
        "merge12=merge11.append(ch)\n",
        "merge13=merge12.append(ha)\n",
        "merge14=merge13.append(tn)\n",
        "\n",
        "merge14.to_excel('Sparkling_Data_Update_for_Feb_Power_BI_Consolidated_new.xlsx',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1svsnrkZ2XS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########Hydration Merge######################\n",
        "wb = pd.read_excel('Hydration_Feb_Results_WB.xlsx',sheet_name='Power_BI') \n",
        "# de = pd.read_excel('Hydration_Feb_Results_DE.xlsx',sheet_name='Power_BI')  \n",
        "mh = pd.read_excel('Hydration_Feb_Results_MH.xlsx',sheet_name='Power_BI') \n",
        "ap = pd.read_excel('Hydration_Feb_Results_AP.xlsx',sheet_name='Power_BI') \n",
        "up = pd.read_excel('Hydration_Feb_Results_UP.xlsx',sheet_name='Power_BI') \n",
        "pu = pd.read_excel('Hydration_Feb_Results_PU.xlsx',sheet_name='Power_BI') \n",
        "ka = pd.read_excel('Hydration_Feb_Results_KA.xlsx',sheet_name='Power_BI') \n",
        "gu = pd.read_excel('Hydration_Feb_Results_GU.xlsx',sheet_name='Power_BI') \n",
        "ra = pd.read_excel('Hydration_Feb_Results_RA.xlsx',sheet_name='Power_BI') \n",
        "mp = pd.read_excel('Hydration_Feb_Results_MP.xlsx',sheet_name='Power_BI') \n",
        "orr = pd.read_excel('Hydration_Feb_Results_OR.xlsx',sheet_name='Power_BI') \n",
        "bi = pd.read_excel('Hydration_Feb_Results_BI.xlsx',sheet_name='Power_BI') \n",
        "ch = pd.read_excel('Hydration_Feb_Results_CH.xlsx',sheet_name='Power_BI') \n",
        "# ha = pd.read_excel('Hydration_Feb_Results_HA.xlsx',sheet_name='Power_BI') \n",
        "tn = pd.read_excel('Hydration_Feb_Results_TN.xlsx',sheet_name='Power_BI')\n",
        "\n",
        "# merge1=wb.append(de)\n",
        "merge2=wb.append(mh)\n",
        "merge3=merge2.append(ap)\n",
        "merge4=merge3.append(up)\n",
        "merge5=merge4.append(pu)\n",
        "merge6=merge5.append(ka)\n",
        "merge7=merge6.append(gu)\n",
        "merge8=merge7.append(ra)\n",
        "merge9=merge8.append(mp)\n",
        "merge10=merge9.append(orr)\n",
        "merge11=merge10.append(bi)\n",
        "merge12=merge11.append(ch)\n",
        "# merge13=merge12.append(ha)\n",
        "merge14=merge12.append(tn)\n",
        "\n",
        "merge14.to_excel('Hydration_Data_Update_for_Feb_Power_BI_Consolidated.xlsx',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9krz2nacb75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spk = pd.read_excel('Data_Update_for_Feb_Power_BI_Consolidated.xlsx')\n",
        "juices = pd.read_excel('Juices_Data_Update_for_Feb_Power_BI_Consolidated.xlsx')\n",
        "hyd = pd.read_excel('Hydration_Data_Update_for_Feb_Power_BI_Consolidated.xlsx')\n",
        "\n",
        "consolidated1=spk.append(juices)\n",
        "consolidated2=consolidated1.append(hyd)\n",
        "consolidated2.to_excel('Data_Update_for_Feb_Power_BI_Consolidated_Apr.xlsx',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz4ZA_02n8OW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "10b6770b-dcf5-4f70-fe55-4d085f697f87"
      },
      "source": [
        "dt_raw.columns\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['States', 'Date', 'Tmax', 'Avg_precip', 'Economy', 'Unemployment',\n",
              "       'Total_SPK', 'VolSales', 'month', 'Sales_Index'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsjV4B13n8xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}