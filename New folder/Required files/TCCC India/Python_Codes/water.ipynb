{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "water.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFaynSuravbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAgJ-yHWJy7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy  as np\n",
        "# all_state=['HA']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0gXMKV3J0PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'WB', 'DE', 'MH', 'AP', 'UP', 'PU', 'KA', 'GU', 'RA', 'MP', 'OR', 'TN', 'BI', 'CH', 'HA'\n",
        "all_state = ['WB', 'MH', 'AP','UP', 'PU', 'KA', 'GU', 'RA', 'MP', 'OR', 'BI', 'CH','TN']\n",
        "\n",
        "# all_state = ['WB','DE', 'MH', 'AP', 'UP', 'PU', 'KA', 'GU', 'RA', 'MP', 'OR', 'BI', 'CH','HA','TN']\n",
        "sta_len = len(all_state)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65KmPnWyKLiM",
        "colab_type": "code",
        "outputId": "43fe635c-557d-4354-ec2b-5eff2d649445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##### reading the file ##########################################################\n",
        "for sta in range(sta_len):\n",
        "  \n",
        "  ##### RAW data ######################################################################################\n",
        "  coke_raw = pd.read_excel('CCI_Hydration_Consolidated_Data.xlsx',sheet_name=all_state[sta])    #### load raw data here\n",
        "  dt_raw   = coke_raw.copy()\n",
        "  dt_raw   = dt_raw[dt_raw['Date'] >='2015-01-01'].reset_index(drop=True)  ## date change according to model, format:- YYYY-MM-DD\n",
        "  power_bi = dt_raw.copy()\n",
        "  power_bi['Category'] = 'Hydration'                      # enter category name as needed for power BI\n",
        "  ##### transformed Data ###############################################################################\n",
        "  coke_ols = pd.read_excel('CCI_Hydration_Ensemble_Data.xlsx',sheet_name=all_state[sta])   #### load transformed data here\n",
        "  dt_ols   = coke_ols.copy()\n",
        "  dt_ols   = dt_ols[dt_ols['Date'] >='2015-01-01'].reset_index(drop=True)  ## date change according to model, format:- YYYY-MM-DD\n",
        "  ##### coefficient data ###############################################################################\n",
        "  coef_ols = pd.read_excel('Hydration_coeffs.xlsx', sheet_name =all_state[sta])  #### coefficient data here \n",
        "  dt_coef  = coef_ols.copy() \n",
        "  ######################################################################################################\n",
        "  seed     = pd.read_excel(\"Seed_results_Hydration.xlsx\",sheet_name=all_state[sta])  \n",
        "  rf_seed  = seed.at[0,'RF']               # rf  seed\n",
        "  ann_seed = seed.at[0,'ANN']              # ann seed          \n",
        "  ############################### Dynamic Coefficients ################################################\n",
        "\n",
        "  ##########################################################################################################\n",
        "  date1 = '2019-01-01'       # date from which dynamic callculations be calculated, format = 'YYYY-MM-DD'\n",
        "  date2 = '2018-01-01'       # year back as that of 'date1' \n",
        "\n",
        "  due_to = 4                 # mention number of variables(features no. for elasticity calculation) and used in column selection in Due-to\n",
        "  trans  = [0,0,1,0]         # this array is for log transformation, enter for main features for which we calculate elasticity\n",
        "  \n",
        "  \n",
        "  ##############################################################################################################################################\n",
        "  ##############################################################################################################################################\n",
        "  ####### train and test data for rf+ann model ###########################################\n",
        "  z = coke_ols['VolSales'].dropna().count() - 1\n",
        "  y = z - 3\n",
        "  ######## predicted ols column selection ###########################################\n",
        "  list_ols  = list(coke_ols.columns.values) \n",
        "\n",
        "  col_names = list_ols[2:-1]             # Enter column number here and it should be features\n",
        "  col_count = len(col_names)\n",
        "\n",
        "  ################################################################# OLS:- y = mx + c --- code part\n",
        "  Y = coke_ols['VolSales']\n",
        "\n",
        "  xy = 0\n",
        "  for i in range(col_count):\n",
        "    xy += coef_ols['Estimate'][i+1] * coke_ols[coke_ols.columns[i+2]]\n",
        "\n",
        "  xy = coef_ols['Estimate'][0] + xy\n",
        "\n",
        "\n",
        "  ols_mape = np.mean(np.abs ( (Y - xy)/Y ) * 100)          \n",
        "  print(\"MAPE OLS:\",abs(ols_mape))\n",
        "\n",
        "  coke_ols['OLS_Predicted'] = xy   \n",
        "  #######################################################################################################\n",
        "  ############################# RF + ANN model ##########################################################\n",
        "  #######################################################################################################\n",
        "  states_name = coke_ols['States'].unique()\n",
        "  r2_mape = []\n",
        "\n",
        "  for i in range(len(states_name)):\n",
        "      metric_train=[]\n",
        "      metric_test=[]\n",
        "      state = states_name[i]\n",
        "      print('------------------------------------------------------------------------------------------------------')\n",
        "      print('Processing for state: ',state)\n",
        "      pun_coke  = coke_ols[coke_ols['States'] == state]   # Give your state name here\n",
        "      pun_coke  = pun_coke.reset_index( )\n",
        "      #'Market',add below for 7 new states\n",
        "      pun_coke2 = pun_coke.drop(['States','index'],axis=1)  \n",
        "      x=0\n",
        "      # y=56                                                                        \n",
        "      # z=59                                                                        \n",
        "      train_1 = pun_coke2.iloc[x:y, :]\n",
        "      test_1  = pun_coke2.iloc[y:z, :]\n",
        "      forecast_train = pun_coke2.iloc[x:z, :]\n",
        "      forecast_date  = pun_coke2.iloc[z:, :]\n",
        "      train = train_1.drop(['Date'],axis=1)\n",
        "      test  = test_1.drop(['Date'],axis=1)\n",
        "      metric_train.append(str((train.columns).values.tolist()))\n",
        "      metric_test.append(str((train.columns).values.tolist()))\n",
        "      metric_train.append('TRAIN')\n",
        "      metric_test.append('TEST')\n",
        "      \n",
        "      train_target  = train[['VolSales']]\n",
        "      train_feature = train.drop(['VolSales'], axis=1)\n",
        "      test_target   = test[['VolSales']]\n",
        "      test_feature  = test.drop(['VolSales'], axis=1)\n",
        "\n",
        "      \n",
        "      print(train_feature.shape)\n",
        "      print(train_target.shape)\n",
        "      print(test_feature.shape)\n",
        "      print(test_target.shape)\n",
        "      \n",
        "      ################################## Modelling #######################################################\n",
        "      \n",
        "      def mean_absolute_percentage_error(y_true, y_pred): \n",
        "          y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "          return np.mean(np.abs((y_true - y_pred) / y_true)*100)\n",
        "      \n",
        "  ##################################\n",
        "  ###  \n",
        "  ################################## Random Forest ###########################################\n",
        "      #n_estimators=10,random_state=42\n",
        "      #n_estimators=20,max_depth=5,min_samples_split=5,min_samples_leaf=1,\n",
        "      from sklearn.ensemble import RandomForestRegressor\n",
        "      rf = RandomForestRegressor(random_state=rf_seed)    \n",
        "      rf.fit(train_feature,train_target)\n",
        "      Train_pred_rf = rf.predict(train_feature)\n",
        "      Test_pred_rf  = rf.predict(test_feature)\n",
        "      rf.fit(pun_coke2.iloc[x:z, :].drop(['VolSales','Date'], axis=1),pun_coke2.iloc[x:z, :]['VolSales'])\n",
        "      pred_rf = rf.predict(pun_coke2.iloc[z:, :].drop(['VolSales','Date'], axis=1))\n",
        "      \n",
        "      actual_test=list(test_target['VolSales'])\n",
        "      actual_train=list(train_target['VolSales'])\n",
        "\n",
        "      Train_Results=pd.DataFrame(data=actual_train, columns=['Train_Actual'])\n",
        "      Train_Results.insert(loc=1, column='Train_Pred_RF', value=Train_pred_rf)\n",
        "      Test_Results=pd.DataFrame(data=actual_test, columns=['Test_Actual'])\n",
        "      Test_Results.insert(loc=1, column='Test_Pred_RF', value=Test_pred_rf)\n",
        "      \n",
        "\n",
        "      print(\"                           R_square for training data:\",rf.score(train_feature,train_target))\n",
        "      print(\"                           R_square for testing data:\",rf.score(test_feature,test_target))\n",
        "      print(\"                           MAPE for training data:\",mean_absolute_percentage_error(train_target['VolSales'], Train_pred_rf))\n",
        "      print(\"                           MAPE for testing data:\",mean_absolute_percentage_error(test_target['VolSales'], Test_pred_rf))\n",
        "      print(rf.feature_importances_)\n",
        "      fi=pd.DataFrame(rf.feature_importances_,index=train_feature.columns)\n",
        "      # print(fi)\n",
        "      r2_train=rf.score(train_feature,train_target)\n",
        "      r2_test=rf.score(test_feature,test_target)\n",
        "      mape_train=mean_absolute_percentage_error(train_target['VolSales'], Train_pred_rf)\n",
        "      mape_test=mean_absolute_percentage_error(test_target['VolSales'], Test_pred_rf)\n",
        "      \n",
        "\n",
        "    \n",
        "      metric_train.append(r2_train)\n",
        "      metric_train.append(mape_train)\n",
        "      metric_test.append(r2_test)\n",
        "      metric_test.append(mape_test)\n",
        "\n",
        "      rf_mape = (((mape_train)*y)+((mape_test)*(z-y)))/(z+1)\n",
        "      print(\"RF mape:-\",rf_mape)\n",
        "      \n",
        "      ################################## ANN ##############################################\n",
        "      from sklearn.metrics import r2_score\n",
        "      from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "      model_ann = MLPRegressor(hidden_layer_sizes = (256),max_iter=50, batch_size=1,verbose=0,random_state=ann_seed)\n",
        "      print(model_ann.get_params(deep=True))\n",
        "      \n",
        "      model_ann.fit(train_feature, train_target)\n",
        "\n",
        "      \n",
        "      model_ann.fit(pun_coke2.iloc[x:z, :].drop(['VolSales','Date'], axis=1),pun_coke2.iloc[x:z, :]['VolSales'])\n",
        "      pred_ann = model_ann.predict(pun_coke2.iloc[z:, :].drop(['VolSales','Date'], axis=1))\n",
        "      \n",
        "      Train_pred_ann=model_ann.predict(train_feature)\n",
        "      Test_pred_ann=model_ann.predict(test_feature)\n",
        "      \n",
        "      Train_Results.insert(loc=2, column='Train_Pred_ANN', value=Train_pred_ann)\n",
        "      Test_Results.insert(loc=2, column='Test_Pred_ANN', value=Test_pred_ann)\n",
        "      \n",
        "      \n",
        "      print(\"                R_square for training data:\",r2_score(train_target['VolSales'], Train_pred_ann))\n",
        "      print(\"                R_square for testing data:\",r2_score(test_target['VolSales'], Test_pred_ann))\n",
        "      print(\"                MAPE for training data:\",mean_absolute_percentage_error(train_target['VolSales'], Train_pred_ann))\n",
        "      print(\"                MAPE for testing data:\",mean_absolute_percentage_error(test_target['VolSales'], Test_pred_ann))\n",
        "      \n",
        "      \n",
        "      mape_train=mean_absolute_percentage_error(train_target['VolSales'], Train_pred_ann)\n",
        "      mape_test=mean_absolute_percentage_error(test_target['VolSales'], Test_pred_ann)\n",
        "\n",
        "      ann_mape = (((mape_train)*y)+((mape_test)*(z-y)))/(z+1)\n",
        "      print(\"ANN mape:-\",ann_mape)\n",
        "  #############################################################################################################################\n",
        "  #########################################################\n",
        "  estimatorts_train    = [Train_pred_rf, Train_pred_ann]\n",
        "  estimatorts_test     = [Test_pred_rf, Test_pred_ann]\n",
        "  estimatorts_forecast = [pred_rf,pred_ann]\n",
        "\n",
        "  estimatorts_train    = pd.DataFrame(estimatorts_train).T\n",
        "  estimatorts_test     = pd.DataFrame(estimatorts_test).T\n",
        "  estimatorts_forecast = pd.DataFrame(estimatorts_forecast).T\n",
        "\n",
        "  estimatorts=estimatorts_train.append(estimatorts_test)\n",
        "  estimatorts=estimatorts.append(estimatorts_forecast)\n",
        "\n",
        "  estimatorts = estimatorts.rename(columns={0: 'Pred_RF',1:'Pred_ANN'})\n",
        "\n",
        "  estimatorts=estimatorts.reset_index(drop=True)\n",
        "  estimatorts['Pred_OLS'] = coke_ols['OLS_Predicted']\n",
        "  #####################################################################################################\n",
        "  #################################################################\n",
        "  ###################################################################################\n",
        "  w1=(((ols_mape+rf_mape+ann_mape)**2)/(ols_mape)**2)\n",
        "  w2=(((ols_mape+rf_mape+ann_mape)**2)/(rf_mape)**2)\n",
        "  w3=(((ols_mape+rf_mape+ann_mape)**2)/(ann_mape)**2)\n",
        "\n",
        "  w11=w1/(w1+w2+w3)\n",
        "  w22=w2/(w1+w2+w3)\n",
        "  w33=w3/(w1+w2+w3)\n",
        "\n",
        "\n",
        "  estimatorts[\"Ensemble\"] = (w11*estimatorts[\"Pred_OLS\"]) + (w22*estimatorts[\"Pred_RF\"]) + (w33*estimatorts[\"Pred_ANN\"])\n",
        "  ###########################################################################\n",
        "  e=estimatorts[\"Ensemble\"]                       \n",
        "      \n",
        "  estimatorts = estimatorts.reset_index(drop=True)\n",
        "  estimatorts[\"Ensemble\"] = estimatorts[\"Ensemble\"].reset_index(drop=True)\n",
        "  coke_ols['Ensemble']    = estimatorts[\"Ensemble\"]\n",
        "\n",
        "  e = e.reset_index(drop=True)\n",
        "  Y = Y.reset_index(drop=True)\n",
        "\n",
        "  Ensemble_MAPE=np.mean(np.abs((Y-e)/Y)*100)\n",
        "  print(\"MAPE Ensemble:\",abs(Ensemble_MAPE))\n",
        "  #######################################################################################################################\n",
        "\n",
        "  #################### part of DUE_TO ###################################################################################\n",
        "\n",
        "  #######################################################################################################################\n",
        "\n",
        "  list_df      = list(dt_raw.columns.values)    # columns number that covers raw data's features\n",
        "  dt_col_names = list_df[2:due_to+2]   \n",
        "  dt_col_count = len(dt_col_names)  \n",
        "  due_to_varb  = len(dt_col_names)              # features being used in Due_tos for loop       \n",
        "  sale_ind     = pd.DatetimeIndex(dt_raw['Date']).year.nunique()  # no. of times Sales Index calculation should repeat\n",
        "                                                                                  \n",
        "  ####################### Due-To calculations #######################################################################\n",
        "  ###################################################################################################################\n",
        "\n",
        "  ####################### Due-To calculations #######################################################################\n",
        "\n",
        "  Due_to = pd.DataFrame()\n",
        "  ##### Difference YOY  ###########################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    Due_to[dt_col_names[i]+'_Diff_YOY'] = dt_raw[dt_col_names[i]].diff(periods = 12)\n",
        "  ##### Difference MOM  ########################################################################################################### \n",
        "  for i in range(due_to_varb):\n",
        "    Due_to[dt_col_names[i]+'_Diff_MOM'] = dt_raw[dt_col_names[i]].diff(periods = 1)\n",
        "  ##### DT of variables  ##########################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    Due_to['DT_'+dt_col_names[i]] = (dt_coef['Estimate'][i+1] * dt_ols[dt_ols.columns[i+2]]) - (dt_coef['Estimate'][i+1] * dt_ols[dt_ols.columns[i+2]].shift(12))\n",
        "    Due_to['DT_'+dt_col_names[i]].fillna(0, inplace=True)\n",
        "  ##### % DT variables  ############################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    Due_to['% DT_'+dt_col_names[i]] = ((Due_to['DT_'+dt_col_names[i]]).to_numpy() / (dt_ols['VolSales']).shift(12)) * 100\n",
        "  #### DT sales index  #############################################################################################################\n",
        "  import datetime\n",
        "  dt_raw['month']       = pd.DatetimeIndex(dt_raw['Date']).month\n",
        "  sales_index           = dt_raw[['Date','month','VolSales']]\n",
        "  x = sales_index.groupby(['month']).mean()\n",
        "  dt_raw['Sales']       = pd.DataFrame(np.tile((x['VolSales']/(sales_index['VolSales']).mean()),sale_ind))  \n",
        "  dt_raw['Sales_Index'] = dt_raw['Sales'].shift(12)\n",
        "  dt_raw.drop(['Sales'], axis=1, inplace=True)\n",
        "\n",
        "  for i in range(due_to_varb):\n",
        "    Due_to['DT_'+dt_col_names[i]+'_using_sales_index'] = dt_raw['Sales_Index'] * Due_to['DT_'+dt_col_names[i]]\n",
        "    Due_to['DT_'+dt_col_names[i]+'_using_sales_index'].fillna(0, inplace=True)\n",
        "\n",
        "  for i in range(1):\n",
        "    Due_to['DT Weather Sales Index'] = Due_to['DT_'+dt_col_names[i]+'_using_sales_index'] + Due_to['DT_'+dt_col_names[i+1]+'_using_sales_index'] \n",
        "  ##### DT % sales index  #############################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    Due_to['DT_%'+dt_col_names[i]+'_sales_index'] = ((Due_to['DT_'+dt_col_names[i]+'_using_sales_index']).to_numpy() / (dt_ols['VolSales']).shift(12)) * 100\n",
        "\n",
        "  for i in range(1):\n",
        "    Due_to['DT_%Weather_Sales_Index'] = Due_to['DT_%'+dt_col_names[i]+'_sales_index'] + Due_to['DT_%'+dt_col_names[i+1]+'_sales_index']\n",
        "  ##### DT temp MOM  ##################################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    Due_to['DT_'+dt_col_names[i]+'_MOM'] = Due_to['DT_'+dt_col_names[i]+'_using_sales_index'].diff(periods=1)\n",
        "\n",
        "  Due_to['DT_Weather_MOM'] = Due_to['DT Weather Sales Index'].diff(periods=1)\n",
        "  ##### DT ctualised rolling sums ##################################################################################################################################\n",
        "  Due_to['actualized']=coke_ols.apply(\n",
        "\tlambda row: row['VolSales'] if ~np.isnan(row['VolSales']) else row['Ensemble'],axis=1)\n",
        "\n",
        "  Due_to['actualized_3mm'] = Due_to['actualized'].rolling(3).sum().fillna(0)\n",
        "  Due_to['actualized_6mm'] = Due_to['actualized'].rolling(6).sum().fillna(0)\n",
        "  #######################################################################################################################################\n",
        "  Due_to['3MMT_VolSales'] = coke_ols['VolSales'].rolling(3).sum()\n",
        "  Due_to['3MMT_Ensemble'] = coke_ols['Ensemble'].rolling(3).sum()\n",
        "  Due_to['3MMT_VolSales'] = coke_ols['VolSales'].rolling(3).sum()\n",
        "  Due_to['6MMT_Ensemble'] = coke_ols['Ensemble'].rolling(6).sum()\n",
        "  Due_to['6MMT_VolSales'] = coke_ols['VolSales'].rolling(6).sum()\n",
        "  Due_to['3MMT_Category'] = dt_raw.iloc[:, [6]].rolling(3).sum()\n",
        "  Due_to['6MMT_Category'] = dt_raw.iloc[:, [6]].rolling(6).sum()\n",
        "  intial_rolling = coke_ols.VolSales.rolling(3-1).sum()\n",
        "  intial_rolling = intial_rolling.shift(1)\n",
        "  list1 = coke_ols.Ensemble[2:]\n",
        "  Due_to['3MMT_forecast'] = intial_rolling+list1\n",
        "  Due_to['Error']=(((Due_to['3MMT_VolSales'].to_numpy())/Due_to['3MMT_forecast'])-1)*100\n",
        "\n",
        "\n",
        "\n",
        "  ########################### power Bi DT input--part ################################################################\n",
        "\n",
        "  ########### Diff YOY #####################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi[dt_col_names[i]+'_Diff_YOY'] = Due_to[dt_col_names[i]+'_Diff_YOY']\n",
        "  ########### Diff MOM #####################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi[dt_col_names[i]+'_Diff_MOM'] = Due_to[dt_col_names[i]+'_Diff_MOM']\n",
        "  ########### DT_using sales index #########################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi['DT_'+dt_col_names[i]+'_using_sales_index'] = Due_to['DT_'+dt_col_names[i]+'_using_sales_index']\n",
        "  # power_bi['DT Weather Sales Index'] = Due_to['DT Weather Sales Index']\n",
        "  ########### DT_MOM #######################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi['DT_'+dt_col_names[i]+'_MOM'] = Due_to['DT_'+dt_col_names[i]+'_MOM']\n",
        "  # power_bi['DT_Weather_MOM'] = Due_to['DT_Weather_MOM']\n",
        "  ########### DT_% sales index #############################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi['DT_%'+dt_col_names[i]+'_sales_index'] = Due_to['DT_%'+dt_col_names[i]+'_sales_index']\n",
        "  # power_bi['DT_%Weather_Sales_Index'] = Due_to['DT_%Weather_Sales_Index']\n",
        "  ##########################################################################################################\n",
        "  power_bi['Ensemble'] = coke_ols['Ensemble']\n",
        "  power_bi['Actualised']     = Due_to['actualized']\n",
        "  power_bi['Actualised_3MMT'] = Due_to['actualized_3mm']\n",
        "  power_bi['Actualised_6MMT'] = Due_to['actualized_6mm']\n",
        "  power_bi['3MMT_Ensemble'] = coke_ols['Ensemble'].rolling(3).sum()\n",
        "  power_bi['3MMT_VolSales'] = coke_ols['VolSales'].rolling(3).sum()\n",
        "  power_bi['6MMT_Ensemble'] = coke_ols['Ensemble'].rolling(6).sum()\n",
        "  power_bi['6MMT_VolSales'] = coke_ols['VolSales'].rolling(6).sum()\n",
        "  power_bi['3MMT_Category'] = dt_raw.iloc[:, [6]].rolling(3).sum()\n",
        "  power_bi['6MMT_Category'] = dt_raw.iloc[:, [6]].rolling(6).sum()\n",
        "  power_bi['3MMT_forecast'] = Due_to['3MMT_forecast']\n",
        "  power_bi['Error'] = Due_to['Error']\n",
        "  \n",
        "  ##########################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi[dt_col_names[i]+'3MMT'] = dt_raw[dt_col_names[i]].rolling(3).sum()\n",
        "\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi['3MMT'+dt_col_names[i]+'_using_sales_index'] = Due_to['DT_'+dt_col_names[i]+'_using_sales_index'].rolling(3).sum()\n",
        "  ##############################################################################################################\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi[dt_col_names[i]+'6MMT'] = dt_raw[dt_col_names[i]].rolling(6).sum()\n",
        "\n",
        "  for i in range(due_to_varb):\n",
        "    power_bi['6MMT'+dt_col_names[i]+'_using_sales_index'] = Due_to['DT_'+dt_col_names[i]+'_using_sales_index'].rolling(6).sum()\n",
        "  ##########################################################################################################\n",
        "  ############ power bi melt--part ###############################################################################\n",
        "  df_cat = pd.melt(power_bi, id_vars = ['States','Category', 'Date'], var_name='Metrics')\n",
        "  # df_cat.head(4)\n",
        "\n",
        "  #################################################################################################################\n",
        "  ###################################################################################################################################\n",
        "  ###########################################################################################################################################\n",
        "  ###########################################################################################################################################\n",
        "  estimatorts1 = estimatorts\n",
        "\n",
        "  with pd.ExcelWriter('Hydration_March_Results_{}.xlsx'.format(all_state[sta]),datetime_format  = 'YYYY-MM-DD') as writer:  \n",
        "      coke_ols.to_excel(writer,    index=False, sheet_name = 'Ensemble')        \n",
        "      estimatorts1.to_excel(writer,index=False, sheet_name = 'RF+ANN+OLS')          \n",
        "      Due_to.to_excel(writer,      index=False, sheet_name = 'Due_to')          \n",
        "      power_bi.to_excel(writer,    index=False, sheet_name = 'bi')              \n",
        "      df_cat.to_excel(writer,      index=False, sheet_name = 'Power_BI')\n",
        "      "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAPE OLS: 9.456512130509847\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  West Bengal\n",
            "(59, 10)\n",
            "(59, 1)\n",
            "(3, 10)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9741078307537114\n",
            "                           R_square for testing data: 0.5341628001668668\n",
            "                           MAPE for training data: 2.7676046816413735\n",
            "                           MAPE for testing data: 46.90629201289116\n",
            "[8.85033776e-02 1.31026400e-02 5.46624614e-03 1.85051858e-02\n",
            " 1.39372494e-02 2.67769316e-01 2.02421224e-04 4.32443862e-04\n",
            " 1.39847353e-04 5.91941273e-01]\n",
            "RF mape:- 4.825516702468484\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 3200, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.8070066837795611\n",
            "                R_square for testing data: -4.964573765950125\n",
            "                MAPE for training data: 8.521546286528068\n",
            "                MAPE for testing data: 47.004078441375476\n",
            "ANN mape:- 10.218785178242578\n",
            "MAPE Ensemble: 6.138293205085995\n",
            "MAPE OLS: 8.199044100569807\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Maharashtra\n",
            "(59, 9)\n",
            "(59, 1)\n",
            "(3, 9)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9466208748515572\n",
            "                           R_square for testing data: -0.26535343864196115\n",
            "                           MAPE for training data: 2.13505038880269\n",
            "                           MAPE for testing data: 27.609924829098926\n",
            "[0.14887154 0.01473611 0.11821239 0.06354508 0.04165558 0.34776948\n",
            " 0.00213637 0.00137808 0.26169537]\n",
            "RF mape:- 3.314249959153262\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 3350, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.4036574246744966\n",
            "                R_square for testing data: -110.66714366761947\n",
            "                MAPE for training data: 7.071821935493037\n",
            "                MAPE for testing data: 50.42259342175969\n",
            "ANN mape:- 9.023893245386798\n",
            "MAPE Ensemble: 4.812069968954695\n",
            "MAPE OLS: 4.4387813077650815\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Andhra Pradesh\n",
            "(59, 7)\n",
            "(59, 1)\n",
            "(3, 7)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9867208948632011\n",
            "                           R_square for testing data: 0.057281368653611775\n",
            "                           MAPE for training data: 1.502789632839401\n",
            "                           MAPE for testing data: 10.564898193321731\n",
            "[0.01066329 0.00803741 0.01193466 0.02060058 0.02424718 0.00676904\n",
            " 0.91774784]\n",
            "RF mape:- 1.9104648082141247\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 2680, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9261830617438935\n",
            "                R_square for testing data: -44.68705172313415\n",
            "                MAPE for training data: 3.8908152303560533\n",
            "                MAPE for testing data: 17.89281422248721\n",
            "ANN mape:- 4.49581811521379\n",
            "MAPE Ensemble: 2.657002169019508\n",
            "MAPE OLS: 5.869430499470078\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Uttar Pradesh\n",
            "(59, 7)\n",
            "(59, 1)\n",
            "(3, 7)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9929656139768206\n",
            "                           R_square for testing data: 0.840925573770403\n",
            "                           MAPE for training data: 1.78340882378206\n",
            "                           MAPE for testing data: 11.309671686803796\n",
            "[0.00976429 0.00461109 0.00497711 0.00528857 0.0081827  0.01235388\n",
            " 0.95482236]\n",
            "RF mape:- 2.2087323121198876\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1860, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9641740807342845\n",
            "                R_square for testing data: 0.2719921049995443\n",
            "                MAPE for training data: 3.902056527503778\n",
            "                MAPE for testing data: 10.429789531585683\n",
            "ANN mape:- 4.1509635510711105\n",
            "MAPE Ensemble: 2.7656953495998304\n",
            "MAPE OLS: 6.880433461480977\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Punjab\n",
            "(59, 7)\n",
            "(59, 1)\n",
            "(3, 7)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9933854400104758\n",
            "                           R_square for testing data: 0.39317731575492415\n",
            "                           MAPE for training data: 2.6400079196040704\n",
            "                           MAPE for testing data: 18.058321007143977\n",
            "[0.01476329 0.00471213 0.00866474 0.00726473 0.00304789 0.04243345\n",
            " 0.91911376]\n",
            "RF mape:- 3.3323084171122552\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 4040, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9536737684763921\n",
            "                R_square for testing data: -4.462527201427012\n",
            "                MAPE for training data: 6.713855053265874\n",
            "                MAPE for testing data: 16.889310420585876\n",
            "ANN mape:- 7.0918314191181615\n",
            "MAPE Ensemble: 4.067277925129895\n",
            "MAPE OLS: 8.106459805150829\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Karnataka\n",
            "(59, 9)\n",
            "(59, 1)\n",
            "(3, 9)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9518280517080142\n",
            "                           R_square for testing data: -0.04552249498501104\n",
            "                           MAPE for training data: 2.9341631709537657\n",
            "                           MAPE for testing data: 17.29003828495426\n",
            "[1.00841016e-01 4.33768400e-02 2.04979389e-02 4.49476219e-02\n",
            " 3.26290554e-02 4.57441642e-02 4.23128396e-03 1.46208870e-04\n",
            " 7.07585871e-01]\n",
            "RF mape:- 3.571202253033888\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1990, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.7195860919162594\n",
            "                R_square for testing data: -23.250337593929796\n",
            "                MAPE for training data: 7.75596880497167\n",
            "                MAPE for testing data: 20.399825693704507\n",
            "ANN mape:- 8.234946612292733\n",
            "MAPE Ensemble: 4.943141479209592\n",
            "MAPE OLS: 9.413404871837741\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Gujarat\n",
            "(59, 11)\n",
            "(59, 1)\n",
            "(3, 11)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9615012548858969\n",
            "                           R_square for testing data: 0.4084833030838688\n",
            "                           MAPE for training data: 2.4931717376091354\n",
            "                           MAPE for testing data: 23.451642916104365\n",
            "[1.03448464e-01 4.03730953e-02 1.71011403e-02 4.39372566e-02\n",
            " 5.57039578e-02 9.78861531e-02 9.84003752e-04 3.99042904e-04\n",
            " 2.46322697e-04 4.33311829e-04 6.39487251e-01]\n",
            "RF mape:- 3.4516200201151124\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1710, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.6638227376255198\n",
            "                R_square for testing data: -0.0487157188125118\n",
            "                MAPE for training data: 7.207809538434832\n",
            "                MAPE for testing data: 6.329252436644371\n",
            "ANN mape:- 7.0515638107553675\n",
            "MAPE Ensemble: 4.92085697728522\n",
            "MAPE OLS: 16.617234373870613\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Rajasthan\n",
            "(59, 7)\n",
            "(59, 1)\n",
            "(3, 7)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.96590055363466\n",
            "                           R_square for testing data: 0.34693592884626334\n",
            "                           MAPE for training data: 6.416752680495055\n",
            "                           MAPE for testing data: 8.003187000985456\n",
            "[0.0321209  0.0168317  0.06843917 0.0338734  0.01838901 0.02089977\n",
            " 0.80944606]\n",
            "RF mape:- 6.390443954796264\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1550, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.4799531826120794\n",
            "                R_square for testing data: -19.95656172814326\n",
            "                MAPE for training data: 26.216729093586835\n",
            "                MAPE for testing data: 19.58336128244355\n",
            "ANN mape:- 25.484715878872283\n",
            "MAPE Ensemble: 8.973891310168666\n",
            "MAPE OLS: 13.305697535197892\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Madhya Pradesh\n",
            "(59, 8)\n",
            "(59, 1)\n",
            "(3, 8)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9570481690475175\n",
            "                           R_square for testing data: 0.7564375303941987\n",
            "                           MAPE for training data: 4.616058626546854\n",
            "                           MAPE for testing data: 13.495192225274584\n",
            "[0.26194943 0.03912888 0.02476576 0.07406131 0.02394711 0.03063762\n",
            " 0.01181031 0.53369959]\n",
            "RF mape:- 4.9656037403506055\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 4320, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: -0.12254366462765698\n",
            "                R_square for testing data: 0.38202646652936256\n",
            "                MAPE for training data: 21.106050494626732\n",
            "                MAPE for testing data: 8.265951863262133\n",
            "ANN mape:- 20.15960055194863\n",
            "MAPE Ensemble: 6.136519116883952\n",
            "MAPE OLS: 10.635627536824295\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  orissa\n",
            "(59, 7)\n",
            "(59, 1)\n",
            "(3, 7)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9943194538618411\n",
            "                           R_square for testing data: 0.5743983346198087\n",
            "                           MAPE for training data: 2.853766160468723\n",
            "                           MAPE for testing data: 18.865402381010455\n",
            "[0.02085166 0.00958004 0.06262248 0.01154747 0.0159982  0.07552678\n",
            " 0.80387338]\n",
            "RF mape:- 3.570927152550572\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 3630, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.9309195054045487\n",
            "                R_square for testing data: -3.078868436479957\n",
            "                MAPE for training data: 10.778832388190358\n",
            "                MAPE for testing data: 10.598282702889714\n",
            "ANN mape:- 10.5991422065381\n",
            "MAPE Ensemble: 4.710906122319759\n",
            "MAPE OLS: 10.7672616978351\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Bihar\n",
            "(59, 7)\n",
            "(59, 1)\n",
            "(3, 7)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.983675669425914\n",
            "                           R_square for testing data: 0.8082266014113663\n",
            "                           MAPE for training data: 3.770096556635897\n",
            "                           MAPE for testing data: 12.593152521533147\n",
            "[0.0355108  0.01517865 0.00993729 0.01419164 0.02046104 0.04708857\n",
            " 0.85763202]\n",
            "RF mape:- 4.130399276287577\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 4580, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.620229473952421\n",
            "                R_square for testing data: -1.025671400656365\n",
            "                MAPE for training data: 15.80653279479135\n",
            "                MAPE for testing data: 23.456394314138624\n",
            "ANN mape:- 15.919914568811198\n",
            "MAPE Ensemble: 5.784932187864512\n",
            "MAPE OLS: 7.492821997703834\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Chhattisgarh\n",
            "(59, 7)\n",
            "(59, 1)\n",
            "(3, 7)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9854568564034776\n",
            "                           R_square for testing data: -2.4460168293055986\n",
            "                           MAPE for training data: 3.039153271072111\n",
            "                           MAPE for testing data: 9.339657653343316\n",
            "[0.01040428 0.00974495 0.01356988 0.02460798 0.00285712 0.06209791\n",
            " 0.87671789]\n",
            "RF mape:- 3.290936761163246\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1830, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.896424400465212\n",
            "                R_square for testing data: -52.466593902115115\n",
            "                MAPE for training data: 7.8303208179877775\n",
            "                MAPE for testing data: 15.957929956090945\n",
            "ANN mape:- 8.093059017929392\n",
            "MAPE Ensemble: 4.233580179179918\n",
            "MAPE OLS: 9.775356022903338\n",
            "------------------------------------------------------------------------------------------------------\n",
            "Processing for state:  Tamil Nadu\n",
            "(59, 10)\n",
            "(59, 1)\n",
            "(3, 10)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           R_square for training data: 0.9412199992340775\n",
            "                           R_square for testing data: 0.42429521239206025\n",
            "                           MAPE for training data: 3.0314155517098405\n",
            "                           MAPE for testing data: 25.7679960734818\n",
            "[0.25800154 0.08782005 0.04872896 0.05724021 0.10303034 0.010805\n",
            " 0.00503889 0.00407268 0.00070914 0.42455319]\n",
            "RF mape:- 4.065992155100412\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 1, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': 256, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 50, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1130, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                R_square for training data: 0.5249573424582812\n",
            "                R_square for testing data: -5.248892045303291\n",
            "                MAPE for training data: 8.714896368663478\n",
            "                MAPE for testing data: 13.972187315309299\n",
            "ANN mape:- 8.82691186820751\n",
            "MAPE Ensemble: 5.420932793652231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDqFwxZtrBve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########Hydration Merge######################\n",
        "wb = pd.read_excel('Hydration_March_Results_WB.xlsx',sheet_name='Power_BI') \n",
        "# de = pd.read_excel('Hydration_March_Results_DE.xlsx',sheet_name='Power_BI')  \n",
        "mh = pd.read_excel('Hydration_March_Results_MH.xlsx',sheet_name='Power_BI') \n",
        "ap = pd.read_excel('Hydration_March_Results_AP.xlsx',sheet_name='Power_BI') \n",
        "up = pd.read_excel('Hydration_March_Results_UP.xlsx',sheet_name='Power_BI') \n",
        "pu = pd.read_excel('Hydration_March_Results_PU.xlsx',sheet_name='Power_BI') \n",
        "ka = pd.read_excel('Hydration_March_Results_KA.xlsx',sheet_name='Power_BI') \n",
        "gu = pd.read_excel('Hydration_March_Results_GU.xlsx',sheet_name='Power_BI') \n",
        "ra = pd.read_excel('Hydration_March_Results_RA.xlsx',sheet_name='Power_BI') \n",
        "mp = pd.read_excel('Hydration_March_Results_MP.xlsx',sheet_name='Power_BI') \n",
        "orr = pd.read_excel('Hydration_March_Results_OR.xlsx',sheet_name='Power_BI') \n",
        "bi = pd.read_excel('Hydration_March_Results_BI.xlsx',sheet_name='Power_BI') \n",
        "ch = pd.read_excel('Hydration_March_Results_CH.xlsx',sheet_name='Power_BI') \n",
        "# ha = pd.read_excel('Hydration_March_Results_HA.xlsx',sheet_name='Power_BI') \n",
        "tn = pd.read_excel('Hydration_March_Results_TN.xlsx',sheet_name='Power_BI')\n",
        "\n",
        "# merge1=wb.append(de)\n",
        "merge2=wb.append(mh)\n",
        "merge3=merge2.append(ap)\n",
        "merge4=merge3.append(up)\n",
        "merge5=merge4.append(pu)\n",
        "merge6=merge5.append(ka)\n",
        "merge7=merge6.append(gu)\n",
        "merge8=merge7.append(ra)\n",
        "merge9=merge8.append(mp)\n",
        "merge10=merge9.append(orr)\n",
        "merge11=merge10.append(bi)\n",
        "merge12=merge11.append(ch)\n",
        "# merge13=merge12.append(ha)\n",
        "merge14=merge12.append(tn)\n",
        "\n",
        "merge14.to_excel('Hydration_Data_Update_for_March_Power_BI_Consolidated.xlsx',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osimf0R4dFNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}